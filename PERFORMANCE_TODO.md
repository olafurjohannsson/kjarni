# Kjarni Performance & Architecture Improvements

Comprehensive list of all identified improvements, sorted by priority and complexity.
Generated from full codebase analysis on 2026-01-03.

---

## üî¥ CRITICAL (High Impact, Must Fix)

These issues cause severe performance degradation or memory problems.

### 1. Softmax: 255/256 Threads Idle ‚ö†Ô∏è ‚Üí ‚úÖ **COMPLETED 2026-01-03**
**Priority**: CRITICAL | **Complexity**: MEDIUM | **Impact**: 4-8x speedup | **Effort**: 2-3 days

**Status**: ‚úÖ FIXED - Implemented parallel reduction with binary tree (256‚Üí128‚Üí64‚Üí32‚Üí16‚Üí8‚Üí4‚Üí2‚Üí1)

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/softmax/softmax.wgsl:62`

**Problem** (RESOLVED):
- Uses `workgroup_size(256)` but only 1 thread per row is active
- 99.6% of GPU compute capacity wasted
- Sequential loops for scale, max, exp, sum, normalize

**Solution**:
```wgsl
// Current (BAD):
@compute @workgroup_size(256)
fn main() {
    let row_idx = global_id.x;  // Each thread = 1 row
    for (var i = 0u; i < hidden_size; i++) { /* sequential */ }
}

// Proposed (GOOD):
@compute @workgroup_size(256)
fn main() {
    let row_idx = group_id.x;   // Each workgroup = 1 row
    let tid = local_id.x;       // All 256 threads cooperate
    // Use parallel reduction with shared memory
}
```

**Implementation Steps**:
1. Add shared memory buffer: `var<workgroup> s_data: array<f32, 256>`
2. Parallel max reduction (like rms_norm already does)
3. Parallel exp + sum reduction
4. Parallel normalize
5. Benchmark against current implementation

**Expected Results**:
- Softmax: ~0.5ms ‚Üí ~0.06ms for [128, 4096]
- Used in every layer, compounds across model depth

**Implementation Details**:
- Added shared memory: `var<workgroup> s_max` and `var<workgroup> s_sum` (256 elements each)
- Changed from `global_invocation_id` to `workgroup_id` + `local_invocation_id`
- Phase 1: Parallel scale + max reduction with binary tree
- Phase 2: Parallel exp + sum reduction with binary tree
- Phase 3: Parallel normalize
- Phase 4: Parallel zero padding
- All 256 threads now actively cooperate per row

---

### 2. LayerNorm: Same Thread Utilization Bug ‚ö†Ô∏è ‚Üí ‚úÖ **COMPLETED 2026-01-03**
**Priority**: CRITICAL | **Complexity**: MEDIUM | **Impact**: 4-8x speedup | **Effort**: 2-3 days

**Status**: ‚úÖ FIXED - Implemented parallel reduction for mean and variance computation

**Files**:
- `crates/kjarni-transformers/src/gpu_ops/primitives/layer_norm/layer_norm.wgsl:71`
- `crates/kjarni-transformers/src/gpu_ops/blocks/layer_norm/layer_norm.wgsl:69`

**Problem** (RESOLVED): Identical to softmax - only 1/256 threads active per row

**Solution**: Implement Welford's online algorithm with parallel reduction
```wgsl
// Parallel mean + variance computation
// Pass 1: Parallel sum for mean
// Pass 2: Parallel sum of squared differences for variance
// Pass 3: Parallel normalize and apply gamma/beta
```

**Expected Results**:
- LayerNorm: ~0.4ms ‚Üí ~0.05ms for [128, 768]
- Critical for encoder models (BERT, GPT-2)

**Implementation Details**:
- Added shared memory: `var<workgroup> s_sum` and `var<workgroup> s_sum_sq` (256 elements each)
- Changed from `global_invocation_id` to `workgroup_id` + `local_invocation_id`
- Phase 1: Parallel sum for mean with binary tree reduction
- Phase 2: Parallel sum of squared differences for variance with binary tree reduction
- Phase 3: Parallel normalize and apply gamma/beta (affine transform)
- All 256 threads now actively cooperate per row

---

### 3. Memory Leak: Uniform Buffers Allocated Every Frame üêõ
**Priority**: CRITICAL | **Complexity**: EASY | **Impact**: Memory fragmentation | **Effort**: 4 hours

**Files**:
- `crates/kjarni-transformers/src/gpu_ops/primitives/layer_norm/mod.rs:160`
- `crates/kjarni-transformers/src/gpu_ops/primitives/softmax/mod.rs` (similar pattern)

**Problem**:
```rust
pub fn encode(&self, encoder: &mut wgpu::CommandEncoder, ...) {
    let uniform_buffer = self.context.device.create_buffer_init(...); // ‚ùå LEAK
}
```

**Solution**: Use uniform arena pattern like matmul
```rust
pub struct GpuLayerNorm {
    pipeline: wgpu::ComputePipeline,
    uniform_arena: UniformArena,  // ‚úÖ Reusable buffer pool
}
```

**Implementation**:
1. Copy `UniformArena` pattern from matmul/mod.rs
2. Replace `create_buffer_init` with `uniform_arena.get(size)`
3. Arena automatically reuses buffers across frames

---

### 4. GEMV BF16: K Must Be Even üêõ
**Priority**: CRITICAL | **Complexity**: EASY | **Impact**: Correctness | **Effort**: 2 hours

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/matmul/gemv_bf16.wgsl:126`

**Problem**:
```wgsl
let k_u32_count = info.k / 2u; // NOTE: Assumes K is even!
for (var i = 0u; i < k_u32_count; i = i + 1u) {
    // Processes 2 elements per iteration
}
// ‚ùå If K is odd, last element is silently skipped!
```

**Solution**:
```wgsl
// Handle remainder
if (info.k % 2u == 1u) {
    acc += a_in[info.k - 1u] * get_b_single(n_idx * info.k + info.k - 1u);
}
```

---

## üü† HIGH PRIORITY (High Impact, Should Fix Soon)

### 5. GEMV: Add vec4 Loads for 2x Bandwidth
**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: 2x speedup | **Effort**: 1-2 days

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/matmul/gemv_bf16.wgsl:124`

**Problem**: Currently loads u32 (2x BF16), should load vec4<u32> (8x BF16)

**Solution**:
```wgsl
// Current: 2 BF16 per iteration
let packed_b = b_in[k_u32_start + i];  // u32

// Proposed: 8 BF16 per iteration
let packed_b = vec4<u32>(
    b_in[k_u32_start + i*4u],
    b_in[k_u32_start + i*4u + 1u],
    b_in[k_u32_start + i*4u + 2u],
    b_in[k_u32_start + i*4u + 3u]
);
```

**Impact**: Decode phase (70-80% of inference time) gets 2x faster

---

### 6. Flash Attention Implementation
**Priority**: HIGH | **Complexity**: HARD | **Impact**: 2-4x for long context | **Effort**: 2-3 weeks

**Files**: All attention implementations

**Problem**: Current O(N¬≤) attention doesn't scale to long contexts

**Solution**: Implement Flash Attention 2
- Online softmax (fused with attention matmul)
- Tiling to fit in shared memory
- Reduces memory from O(N¬≤) to O(N)

**Expected Results**:
- 2K context: ~50% faster
- 4K context: ~2x faster
- 8K+ context: ~4x faster

**Resources**:
- Paper: https://arxiv.org/abs/2205.14135
- Reference: PyTorch Flash Attention implementation

---

### 7. INT8 KV Cache Compression
**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: 4x memory reduction | **Effort**: 1 week

**Problem**: KV cache stored in F32/BF16, limiting batch size and context length

**Solution**:
```rust
// Store cache in INT8
struct GpuKVCache {
    k_cache: GpuTensor,  // INT8 quantized
    v_cache: GpuTensor,  // INT8 quantized
    scales: Vec<f32>,    // Per-token quantization scales
}

// Dequantize on-the-fly during attention
fn attention_with_cache(query: &GpuTensor, cache: &GpuKVCache) {
    let k_dequant = dequantize_int8(cache.k_cache, cache.scales);
    // Use dequantized K for attention
}
```

**Expected Results**:
- Llama 7B with 4K context: 2GB ‚Üí 512MB KV cache
- Enables 4x larger batch sizes or 4x longer contexts

---

### 8. Error Handling: Replace .expect() with Result
**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: Production stability | **Effort**: 1 week

**Problem**: Many `.expect()` calls throughout codebase cause panics on errors

**Files**: Search for `.expect(` across codebase (~50+ occurrences)

**Solution**:
```rust
// Current (BAD):
let tensor = weights.get(name).expect("Weight not found"); // ‚ùå Panic

// Proposed (GOOD):
let tensor = weights.get(name)
    .with_context(|| format!("Missing weight: {}", name))?; // ‚úÖ Proper error
```

**Implementation**:
1. Audit all `.expect()` calls
2. Replace with proper `Result` returns
3. Use `anyhow::Context` for error context
4. Add error recovery where possible

---

## üü° MEDIUM PRIORITY (Good Improvements)

### 9. Matmul: Double Buffering
**Priority**: MEDIUM | **Complexity**: MEDIUM | **Impact**: 10-15% speedup | **Effort**: 3-4 days

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/matmul/matmul_bf16.wgsl:32`

**Solution**: Overlap compute with next tile load
```wgsl
// Load tile N+1 while computing tile N
// Requires double-buffered shared memory
var<workgroup> a_tile_0: array<f32, 1024>;
var<workgroup> a_tile_1: array<f32, 1024>;
var<workgroup> current_buffer: u32 = 0u;
```

---

### 10. Matmul: Increase Tile Size for Large Matrices
**Priority**: MEDIUM | **Complexity**: MEDIUM | **Impact**: 15-20% for M,N,K > 8K | **Effort**: 1 week

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/matmul/matmul_bf16.wgsl:68`

**Current**: 32x32 tiles
**Proposed**: Adaptive tile size (64x64 or 128x128 for large matrices)

**Requires**: Profiling to find optimal tile sizes per GPU

---

### 11. RoPE: Increase Workgroup Size
**Priority**: MEDIUM | **Complexity**: EASY | **Impact**: 20-30% speedup | **Effort**: 2 hours

**Files**:
- `crates/kjarni-transformers/src/gpu_ops/blocks/rope/rope.wgsl:24`
- `crates/kjarni-transformers/src/gpu_ops/blocks/rope/rope_single.wgsl:18`

**Current**: `workgroup_size(16, 1, 1)` - very small
**Proposed**: `workgroup_size(64, 1, 1)` or `workgroup_size(128, 1, 1)`

**Benefit**: Better GPU occupancy, reduces kernel launch overhead

---

### 12. RoPE: Vec2 Loads/Stores
**Priority**: MEDIUM | **Complexity**: EASY | **Impact**: 2x bandwidth | **Effort**: 4 hours

**Solution**:
```wgsl
// Current: Process one dimension pair
let v0 = tensor_in[base_idx + dim_idx];
let v1 = tensor_in[base_idx + dim_idx + half_dim];

// Proposed: Load as vec2
let v = vec2<f32>(
    tensor_in[base_idx + dim_idx],
    tensor_in[base_idx + dim_idx + half_dim]
);
```

---

### 13. Add BF16 Weight Support to FC1/FC2
**Priority**: MEDIUM | **Complexity**: MEDIUM | **Impact**: 2x memory bandwidth | **Effort**: 3 days

**Files**:
- `crates/kjarni-transformers/src/gpu_ops/blocks/ffn/fc1.wgsl`
- `crates/kjarni-transformers/src/gpu_ops/blocks/ffn/fc2.wgsl`

**Current**: F32 only
**Proposed**: Support BF16 weights like matmul does

---

### 14. Fused SwiGLU: Reduce Shared Memory
**Priority**: MEDIUM | **Complexity**: EASY | **Impact**: GPU compatibility | **Effort**: 2 hours

**File**: `crates/kjarni-transformers/src/gpu_ops/blocks/ffn_swiglu/swiglu_fused.wgsl:23`

**Current**: 8192 floats (32KB)
**Proposed**: 4096 floats (16KB) for better compatibility

**Note**: Many GPUs have 16KB shared memory limit per workgroup

---

### 15. Repeat KV: Vec4 Loads
**Priority**: MEDIUM | **Complexity**: EASY | **Impact**: 4x bandwidth | **Effort**: 3 hours

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/repeat_kv/repeat_kv.wgsl:84`

**Solution**:
```wgsl
// Process 4 elements per thread instead of 1
let output_idx = global_id.x * 4u;
let vals = vec4<f32>(
    input_kv[input_idx],
    input_kv[input_idx + 1u],
    input_kv[input_idx + 2u],
    input_kv[input_idx + 3u]
);
```

---

### 16. Apply Mask: Use -inf Instead of -1e9
**Priority**: MEDIUM | **Complexity**: EASY | **Impact**: Numerical stability | **Effort**: 10 minutes

**File**: `crates/kjarni-transformers/src/gpu_ops/primitives/apply_mask/apply_mask.wgsl:124`

**Current**: `scores[score_idx] = -1e9;`
**Proposed**: `scores[score_idx] = -3.402823e+38;` (F32 -inf)

**Note**: -1e9 might not be sufficient for very large score values

---

## üü¢ LOW PRIORITY (Nice to Have)

### 17. Embedding Vec4 Loads
**Priority**: LOW | **Complexity**: EASY | **Impact**: 10-20% | **Effort**: 3 hours

**Files**:
- `crates/kjarni-transformers/src/gpu_ops/primitives/lookup/lookup.wgsl`
- `crates/kjarni-transformers/src/gpu_ops/primitives/lookup2/lookup2.wgsl`

---

### 18. Subgroup Operations for Reductions
**Priority**: LOW | **Complexity**: MEDIUM | **Impact**: 20-30% for reductions | **Effort**: 1 week

**Applies to**: softmax, layer_norm, rms_norm

**Requires**: WebGPU subgroup extension support

---

### 19. Profile and Optimize erf() Approximation
**Priority**: LOW | **Complexity**: MEDIUM | **Impact**: 10% for GELU | **Effort**: 2 days

**File**: `crates/kjarni-transformers/src/gpu_ops/blocks/ffn/fc1.wgsl:27`

**Current**: Abramowitz & Stegun approximation (accurate to 1.5e-7)
**Alternative**: Polynomial approximation (faster but less accurate)

---

### 20. Fuse Operations
**Priority**: LOW | **Complexity**: HARD | **Impact**: Varies | **Effort**: Varies

**Opportunities**:
- Fuse RoPE with attention matmul
- Fuse softmax with apply_mask
- Fuse LayerNorm with residual addition
- Fuse FFN with residual addition

**Trade-off**: Reduced flexibility, increased kernel complexity

---

## üìä Impact Summary

| Priority | Count | Completed | Remaining Effort | Expected Speedup |
|----------|-------|-----------|------------------|------------------|
| CRITICAL | 4     | 2 ‚úÖ      | 3-5 days         | 8-16x (cumulative) |
| HIGH     | 4     | 0         | 4-6 weeks        | 2-4x |
| MEDIUM   | 12    | 0         | 3-4 weeks        | 1.5-2x |
| LOW      | 6     | 0         | 2-3 weeks        | 1.1-1.3x |

**Completed Items**: Softmax threading fix (#1), LayerNorm threading fix (#2)

---

## üéØ Recommended Implementation Order

**Week 1-2: Critical Fixes**
1. ‚úÖ Fix softmax threading (CRITICAL) - COMPLETED 2026-01-03
2. ‚úÖ Fix LayerNorm threading (CRITICAL) - COMPLETED 2026-01-03
3. Fix memory leaks (CRITICAL)
4. Fix GEMV K-odd bug (CRITICAL)

**Week 3-4: High-Impact Optimizations**
5. Add vec4 loads to GEMV (HIGH)
6. Start INT8 KV cache (HIGH)
7. Start Flash Attention implementation (HIGH)

**Week 5-6: Medium-Priority Improvements**
8. BF16 support for FC1/FC2 (MEDIUM)
9. Increase RoPE workgroup size (MEDIUM)
10. Double buffering for matmul (MEDIUM)

**Ongoing: Low Priority**
11. Profile and optimize as needed (LOW)
12. Fuse operations where beneficial (LOW)

---

## üìù Notes

- All line numbers are accurate as of 2026-01-03
- Performance measurements on RTX 3090 (24GB VRAM)
- Complexity estimates assume familiarity with WebGPU/WGSL
- Expected speedups are approximate and should be validated with benchmarks
- Some improvements require GPU features (subgroups) that may not be universally available

---

## üîç Testing Strategy

For each improvement:
1. **Unit test**: Verify correctness with known inputs
2. **Benchmark**: Compare against baseline (current implementation)
3. **Integration test**: Run full model inference, check output quality
4. **Profile**: Use GPU profilers (NSight, RenderDoc) to verify improvement

---

**Generated by**: Claude Code analysis session
**Last updated**: 2026-01-03
**Total issues identified**: 20
**Issues completed**: 2 (Softmax threading, LayerNorm threading)
**Total shaders documented**: 20 of 39
