//! Core Reranker implementation.

use std::path::Path;
use std::sync::Arc;

use kjarni_transformers::{WgpuContext, models::ModelType, traits::Device};

use crate::CrossEncoder;
use crate::common::{default_cache_dir, ensure_model_downloaded};

use super::builder::RerankerBuilder;
use super::types::{RerankOverrides, RerankResult, RerankerError, RerankerResult};
use super::validation::validate_for_reranking;

/// High-level text reranker using cross-encoder models.
///
/// Cross-encoders process query-document pairs together, producing
/// more accurate relevance scores than bi-encoder similarity.
pub struct Reranker {
    /// The underlying cross-encoder.
    inner: CrossEncoder,

    /// Model identifier.
    model_id: String,

    /// Model type (None if loaded from path).
    model_type: Option<ModelType>,

    /// Default overrides.
    default_overrides: RerankOverrides,

    /// Device.
    device: Device,

    /// GPU context if using GPU.
    #[allow(dead_code)]
    context: Option<Arc<WgpuContext>>,
}

impl Reranker {
    /// Create a Reranker with default settings.
    ///
    /// Uses CPU, downloads model if needed.
    pub async fn new(model: &str) -> RerankerResult<Self> {
        Self::builder(model).build().await
    }

    /// Load a reranker from a local path.
    ///
    /// # Example
    ///
    /// ```ignore
    /// let reranker = Reranker::from_path("/models/my-cross-encoder")
    ///     .build()
    ///     .await?;
    /// ```
    pub fn from_path(path: impl Into<std::path::PathBuf>) -> RerankerBuilder {
        RerankerBuilder::new("custom").model_path(path)
    }

    /// Internal: construct from builder.
    pub(crate) async fn from_builder(builder: RerankerBuilder) -> RerankerResult<Self> {
        let device = builder.device.to_device();

        // Create GPU context if needed
        let context = if device == Device::Wgpu {
            if let Some(ctx) = builder.context {
                Some(ctx)
            } else {
                Some(
                    WgpuContext::new()
                        .await
                        .map_err(|_| RerankerError::GpuUnavailable)?,
                )
            }
        } else {
            None
        };

        let load_config = builder.load_config.map(|c| c.into_inner());

        // Determine loading strategy
        let (inner, model_type, model_id) = if let Some(model_path) = &builder.model_path {
            // Load from local path
            Self::load_from_path(
                model_path,
                device,
                context.clone(),
                load_config,
                builder.quiet,
            )
            .await?
        } else {
            // Load from registry
            Self::load_from_registry(
                &builder.model,
                builder.cache_dir.as_deref(),
                device,
                context.clone(),
                load_config,
                builder.download_policy,
                builder.quiet,
            )
            .await?
        };

        Ok(Self {
            inner,
            model_id,
            model_type,
            default_overrides: builder.overrides,
            device,
            context,
        })
    }

    /// Load reranker from registry.
    async fn load_from_registry(
        model: &str,
        cache_dir: Option<&Path>,
        device: Device,
        context: Option<Arc<WgpuContext>>,
        load_config: Option<kjarni_transformers::models::base::ModelLoadConfig>,
        download_policy: crate::common::DownloadPolicy,
        quiet: bool,
    ) -> RerankerResult<(CrossEncoder, Option<ModelType>, String)> {
        let model_type = ModelType::resolve(model).map_err(RerankerError::UnknownModel)?;

        // Validate for reranking
        validate_for_reranking(model_type)?;

        // Ensure downloaded
        let cache_dir_path = cache_dir
            .map(|p| p.to_path_buf())
            .unwrap_or_else(default_cache_dir);

        ensure_model_downloaded(model_type, Some(&cache_dir_path), download_policy, quiet)
            .await
            .map_err(|e| match e {
                crate::common::KjarniError::ModelNotDownloaded(m) => {
                    RerankerError::ModelNotDownloaded(m)
                }
                crate::common::KjarniError::DownloadFailed { model, source } => {
                    RerankerError::DownloadFailed { model, source }
                }
                other => RerankerError::RerankingFailed(other.into()),
            })?;

        let inner = CrossEncoder::from_registry(
            model_type,
            Some(cache_dir_path),
            device,
            context,
            load_config,
        )
        .await
        .map_err(|e| RerankerError::LoadFailed {
            model: model.to_string(),
            source: e,
        })?;

        Ok((inner, Some(model_type), model.to_string()))
    }

    /// Load reranker from local path.
    async fn load_from_path(
        path: &Path,
        device: Device,
        context: Option<Arc<WgpuContext>>,
        load_config: Option<kjarni_transformers::models::base::ModelLoadConfig>,
        quiet: bool,
    ) -> RerankerResult<(CrossEncoder, Option<ModelType>, String)> {
        // Validate path exists
        if !path.exists() {
            return Err(RerankerError::ModelPathNotFound(path.display().to_string()));
        }

        // Check for required files
        let config_path = path.join("config.json");
        if !config_path.exists() {
            return Err(RerankerError::InvalidConfig(format!(
                "config.json not found in {}",
                path.display()
            )));
        }

        let tokenizer_path = path.join("tokenizer.json");
        if !tokenizer_path.exists() {
            return Err(RerankerError::InvalidConfig(format!(
                "tokenizer.json not found in {}",
                path.display()
            )));
        }

        if !quiet {
            eprintln!("Loading reranker from {}...", path.display());
        }

        let inner = CrossEncoder::from_pretrained(path, device, context, load_config, None)
            .map_err(|e| RerankerError::LoadFailed {
                model: path.display().to_string(),
                source: e,
            })?;

        let model_id = path
            .file_name()
            .map(|s| s.to_string_lossy().to_string())
            .unwrap_or_else(|| "custom".to_string());

        Ok((inner, None, model_id))
    }

    /// Score a single query-document pair.
    pub async fn score(&self, query: &str, document: &str) -> RerankerResult<f32> {
        self.inner
            .predict_pair(query, document)
            .await
            .map_err(RerankerError::RerankingFailed)
    }

    /// Score multiple query-document pairs.
    pub async fn score_pairs(&self, pairs: &[(&str, &str)]) -> RerankerResult<Vec<f32>> {
        self.inner
            .predict_pairs(pairs)
            .await
            .map_err(RerankerError::RerankingFailed)
    }

    /// Rerank documents by relevance to a query.
    pub async fn rerank(
        &self,
        query: &str,
        documents: &[&str],
    ) -> RerankerResult<Vec<RerankResult>> {
        self.rerank_with_config(query, documents, &RerankOverrides::default())
            .await
    }

    /// Rerank with custom overrides.
    pub async fn rerank_with_config(
        &self,
        query: &str,
        documents: &[&str],
        overrides: &RerankOverrides,
    ) -> RerankerResult<Vec<RerankResult>> {
        if documents.is_empty() {
            return Ok(vec![]);
        }

        let merged = self.merge_overrides(overrides);

        // Get raw scores
        let ranked = self
            .inner
            .rerank(query, documents)
            .await
            .map_err(RerankerError::RerankingFailed)?;

        // Convert to results and apply filters
        let mut results: Vec<RerankResult> = ranked
            .into_iter()
            .filter(|(_, score)| merged.threshold.map(|t| *score >= t).unwrap_or(true))
            .map(|(index, score)| RerankResult {
                index,
                score,
                document: documents[index].to_string(),
            })
            .collect();

        // Apply top_k
        if let Some(k) = merged.top_k {
            results.truncate(k);
        }

        Ok(results)
    }

    /// Rerank and return only top-k results.
    pub async fn rerank_top_k(
        &self,
        query: &str,
        documents: &[&str],
        k: usize,
    ) -> RerankerResult<Vec<RerankResult>> {
        self.rerank_with_config(
            query,
            documents,
            &RerankOverrides {
                top_k: Some(k),
                ..Default::default()
            },
        )
        .await
    }

    /// Rerank with a minimum score threshold.
    pub async fn rerank_with_threshold(
        &self,
        query: &str,
        documents: &[&str],
        threshold: f32,
    ) -> RerankerResult<Vec<RerankResult>> {
        self.rerank_with_config(
            query,
            documents,
            &RerankOverrides {
                threshold: Some(threshold),
                ..Default::default()
            },
        )
        .await
    }

    /// Rerank
    pub async fn rerank_owned(
        &self,
        query: &str,
        documents: &[String],
    ) -> RerankerResult<Vec<RerankResult>> {
        let doc_refs: Vec<&str> = documents.iter().map(|s| s.as_str()).collect();
        self.rerank(query, &doc_refs).await
    }

    /// Get the model identifier.
    pub fn model_id(&self) -> &str {
        &self.model_id
    }

    /// Get the model type (None if loaded from path).
    pub fn model_type(&self) -> Option<ModelType> {
        self.model_type
    }

    /// Get the model's CLI name (if from registry).
    pub fn model_name(&self) -> &str {
        self.model_type
            .map(|t| t.cli_name())
            .unwrap_or(&self.model_id)
    }

    /// Get the device.
    pub fn device(&self) -> Device {
        self.device
    }

    /// Get maximum sequence length.
    pub fn max_seq_length(&self) -> usize {
        self.inner.max_seq_length()
    }

    /// Get the hidden size.
    pub fn hidden_size(&self) -> usize {
        self.inner.hidden_size()
    }
    fn merge_overrides(&self, runtime: &RerankOverrides) -> RerankOverrides {
        RerankOverrides {
            top_k: runtime.top_k.or(self.default_overrides.top_k),
            threshold: runtime.threshold.or(self.default_overrides.threshold),
            return_raw_scores: runtime.return_raw_scores
                || self.default_overrides.return_raw_scores,
            batch_size: runtime.batch_size.or(self.default_overrides.batch_size),
        }
    }
}
