<!doctype html><html><head><meta name='viewport' content='width=device-width,initial-scale=1'><meta charset='UTF-8'><link rel='stylesheet' type='text/css' href='../../../../../../../../../../../../style.css'><script src='../../../../../../../../../../../../control.js'></script></head><body><h2>Coverage Report</h2><h4>Created: 2025-12-04 22:30</h4><span class='control'><a href='javascript:next_line()'>next uncovered line (L)</a>, <a href='javascript:next_region()'>next uncovered region (R)</a>, <a href='javascript:next_branch()'>next uncovered branch (B)</a></span><div class='centered'><table><div class='source-name-title'><pre>/home/olafurj/dev/edgebert/crates-internal/edgetransformers/src/gpu_ops/blocks/cache/reorder/tests.rs</pre></div><tr><td><pre>Line</pre></td><td><pre>Count</pre></td><td><pre>Source</pre></td></tr><tr><td class='line-number'><a name='L1' href='#L1'><pre>1</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_context::WgpuContext;</pre></td></tr><tr><td class='line-number'><a name='L2' href='#L2'><pre>2</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_ops::blocks::cache::reorder::GpuReorderCache;</pre></td></tr><tr><td class='line-number'><a name='L3' href='#L3'><pre>3</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_ops::GpuTensor;</pre></td></tr><tr><td class='line-number'><a name='L4' href='#L4'><pre>4</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use anyhow::Result;</pre></td></tr><tr><td class='line-number'><a name='L5' href='#L5'><pre>5</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use ndarray::{s, Array, Array1, Array4, Axis, Ix4};</pre></td></tr><tr><td class='line-number'><a name='L6' href='#L6'><pre>6</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use std::sync::Arc;</pre></td></tr><tr><td class='line-number'><a name='L7' href='#L7'><pre>7</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L8' href='#L8'><pre>8</pre></a></td><td class='skipped-line'></td><td class='code'><pre>// Helper to read a GpuTensor back to the CPU for comparison.</pre></td></tr><tr><td class='line-number'><a name='L9' href='#L9'><pre>9</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>async fn read_gpu_tensor(tensor: &amp;GpuTensor) -&gt; Result&lt;Array4&lt;f32&gt;&gt; {</pre></td></tr><tr><td class='line-number'><a name='L10' href='#L10'><pre>10</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    let shape = tensor.shape().to_vec();</pre></td></tr><tr><td class='line-number'><a name='L11' href='#L11'><pre>11</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    let raw_data = tensor.read_raw_data().await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L12' href='#L12'><pre>12</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    let data_slice: &amp;[f32] = bytemuck::cast_slice(&amp;raw_data);</pre></td></tr><tr><td class='line-number'><a name='L13' href='#L13'><pre>13</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    Ok(Array4::from_shape_vec((shape[0], shape[1], shape[2], shape[3]), data_slice.to_vec())<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>)</pre></td></tr><tr><td class='line-number'><a name='L14' href='#L14'><pre>14</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L15' href='#L15'><pre>15</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L16' href='#L16'><pre>16</pre></a></td><td class='skipped-line'></td><td class='code'><pre>#[tokio::test]</pre></td></tr><tr><td class='line-number'><a name='L17' href='#L17'><pre>17</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>async fn test_gpu_reorder_cache_parity() -&gt; Result&lt;()&gt; {</pre></td></tr><tr><td class='line-number'><a name='L18' href='#L18'><pre>18</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let context = WgpuContext::new().await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L19' href='#L19'><pre>19</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let reorder_kernel = GpuReorderCache::new(&amp;context);</pre></td></tr><tr><td class='line-number'><a name='L20' href='#L20'><pre>20</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L21' href='#L21'><pre>21</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 1. SETUP ---</pre></td></tr><tr><td class='line-number'><a name='L22' href='#L22'><pre>22</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Let&apos;s simulate a cache with 4 beams (batch_size = 4).</pre></td></tr><tr><td class='line-number'><a name='L23' href='#L23'><pre>23</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let (num_beams, num_heads, seq_len, head_dim) = (4, 2, 5, 8);</pre></td></tr><tr><td class='line-number'><a name='L24' href='#L24'><pre>24</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L25' href='#L25'><pre>25</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Create a source tensor where each beam has a unique, identifiable value.</pre></td></tr><tr><td class='line-number'><a name='L26' href='#L26'><pre>26</pre></a></td><td class='covered-line'><pre>320</pre></td><td class='code'><pre>    let <div class='tooltip'>source_cpu<span class='tooltip-content'>1</span></div> = <div class='tooltip'>Array4::from_shape_fn<span class='tooltip-content'>1</span></div>(<div class='tooltip'>(<span class='tooltip-content'>1</span></div><div class='tooltip'>num_beams<span class='tooltip-content'>1</span></div>, <div class='tooltip'>num_heads<span class='tooltip-content'>1</span></div>, seq_len, head_dim), |(b, _, _, _)| {</pre></td></tr><tr><td class='line-number'><a name='L27' href='#L27'><pre>27</pre></a></td><td class='covered-line'><pre>320</pre></td><td class='code'><pre>        (b as f32 + 1.0) * 100.0 // Beam 0 -&gt; 100.0, Beam 1 -&gt; 200.0, etc.</pre></td></tr><tr><td class='line-number'><a name='L28' href='#L28'><pre>28</pre></a></td><td class='covered-line'><pre>320</pre></td><td class='code'><pre>    });</pre></td></tr><tr><td class='line-number'><a name='L29' href='#L29'><pre>29</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let source_gpu = GpuTensor::from_ndarray(&amp;context, &amp;source_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L30' href='#L30'><pre>30</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    </pre></td></tr><tr><td class='line-number'><a name='L31' href='#L31'><pre>31</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 2. DEFINE THE REORDERING ---</pre></td></tr><tr><td class='line-number'><a name='L32' href='#L32'><pre>32</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // This is the `parent_indices` from a beam search step.</pre></td></tr><tr><td class='line-number'><a name='L33' href='#L33'><pre>33</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // New beam 0 comes from old beam 2.</pre></td></tr><tr><td class='line-number'><a name='L34' href='#L34'><pre>34</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // New beam 1 comes from old beam 0.</pre></td></tr><tr><td class='line-number'><a name='L35' href='#L35'><pre>35</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // New beam 2 comes from old beam 2.</pre></td></tr><tr><td class='line-number'><a name='L36' href='#L36'><pre>36</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // New beam 3 comes from old beam 1.</pre></td></tr><tr><td class='line-number'><a name='L37' href='#L37'><pre>37</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let parent_indices_cpu = Array1::from(vec![2u32, 0, 2, 1]);</pre></td></tr><tr><td class='line-number'><a name='L38' href='#L38'><pre>38</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let indices_gpu = GpuTensor::from_ndarray(&amp;context, &amp;parent_indices_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L39' href='#L39'><pre>39</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L40' href='#L40'><pre>40</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 3. CPU GROUND TRUTH ---</pre></td></tr><tr><td class='line-number'><a name='L41' href='#L41'><pre>41</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Manually construct the expected output tensor.</pre></td></tr><tr><td class='line-number'><a name='L42' href='#L42'><pre>42</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let mut expected_cpu = Array4::zeros(source_cpu.dim());</pre></td></tr><tr><td class='line-number'><a name='L43' href='#L43'><pre>43</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>    for i in 0..<div class='tooltip'>num_beams<span class='tooltip-content'>1</span></div> {</pre></td></tr><tr><td class='line-number'><a name='L44' href='#L44'><pre>44</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let parent_idx = parent_indices_cpu[i] as usize;</pre></td></tr><tr><td class='line-number'><a name='L45' href='#L45'><pre>45</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let mut dest_slice = expected_cpu.slice_mut(s![i, .., .., ..]);</pre></td></tr><tr><td class='line-number'><a name='L46' href='#L46'><pre>46</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let src_slice = source_cpu.slice(s![parent_idx, .., .., ..]);</pre></td></tr><tr><td class='line-number'><a name='L47' href='#L47'><pre>47</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        dest_slice.assign(&amp;src_slice);</pre></td></tr><tr><td class='line-number'><a name='L48' href='#L48'><pre>48</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L49' href='#L49'><pre>49</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L50' href='#L50'><pre>50</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 4. GPU EXECUTION ---</pre></td></tr><tr><td class='line-number'><a name='L51' href='#L51'><pre>51</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let output_gpu = GpuTensor::uninitialized(&amp;context, source_cpu.shape().to_vec(), source_gpu.dtype(), &quot;Reorder Dst&quot;);</pre></td></tr><tr><td class='line-number'><a name='L52' href='#L52'><pre>52</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L53' href='#L53'><pre>53</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let mut encoder = context.device.create_command_encoder(&amp;Default::default());</pre></td></tr><tr><td class='line-number'><a name='L54' href='#L54'><pre>54</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    reorder_kernel.encode(&amp;mut encoder, &amp;source_gpu, &amp;output_gpu, &amp;indices_gpu, seq_len);</pre></td></tr><tr><td class='line-number'><a name='L55' href='#L55'><pre>55</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    context.queue.submit(Some(encoder.finish()));</pre></td></tr><tr><td class='line-number'><a name='L56' href='#L56'><pre>56</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L57' href='#L57'><pre>57</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 5. COMPARE RESULTS ---</pre></td></tr><tr><td class='line-number'><a name='L58' href='#L58'><pre>58</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let actual_gpu_result = read_gpu_tensor(&amp;output_gpu).await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L59' href='#L59'><pre>59</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    </pre></td></tr><tr><td class='line-number'><a name='L60' href='#L60'><pre>60</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // For a data copy operation, the results should be exact.</pre></td></tr><tr><td class='line-number'><a name='L61' href='#L61'><pre>61</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    assert_eq!(expected_cpu, actual_gpu_result, <div class='tooltip'><span class='region red'>&quot;GPU reorder result does not match CPU ground truth.&quot;</span><span class='tooltip-content'>0</span></div>);</pre></td></tr><tr><td class='line-number'><a name='L62' href='#L62'><pre>62</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L63' href='#L63'><pre>63</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    println!(&quot;✅ GpuReorderCache passed parity test!&quot;);</pre></td></tr><tr><td class='line-number'><a name='L64' href='#L64'><pre>64</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    Ok(())</pre></td></tr><tr><td class='line-number'><a name='L65' href='#L65'><pre>65</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L66' href='#L66'><pre>66</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L67' href='#L67'><pre>67</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L68' href='#L68'><pre>68</pre></a></td><td class='skipped-line'></td><td class='code'><pre>#[tokio::test]</pre></td></tr><tr><td class='line-number'><a name='L69' href='#L69'><pre>69</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>async fn test_reorder_at_step_2_failure_simulation() -&gt; Result&lt;()&gt; {</pre></td></tr><tr><td class='line-number'><a name='L70' href='#L70'><pre>70</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    println!(&quot;\n=== Simulating Reorder Failure at Step 2 ===\n&quot;);</pre></td></tr><tr><td class='line-number'><a name='L71' href='#L71'><pre>71</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let context = WgpuContext::new().await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L72' href='#L72'><pre>72</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let reorder_kernel = GpuReorderCache::new(&amp;context);</pre></td></tr><tr><td class='line-number'><a name='L73' href='#L73'><pre>73</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L74' href='#L74'><pre>74</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 1. SETUP: State at the START of Step 2 ---</pre></td></tr><tr><td class='line-number'><a name='L75' href='#L75'><pre>75</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // From your logs, seq_length is 2.</pre></td></tr><tr><td class='line-number'><a name='L76' href='#L76'><pre>76</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    const CURRENT_SEQ_LEN: usize = 2;</pre></td></tr><tr><td class='line-number'><a name='L77' href='#L77'><pre>77</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let (num_beams, num_heads, capacity, head_dim) = (4, 16, 142, 64);</pre></td></tr><tr><td class='line-number'><a name='L78' href='#L78'><pre>78</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L79' href='#L79'><pre>79</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Create a source cache that represents the state before reordering.</pre></td></tr><tr><td class='line-number'><a name='L80' href='#L80'><pre>80</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Each beam&apos;s history is identifiable.</pre></td></tr><tr><td class='line-number'><a name='L81' href='#L81'><pre>81</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Beam 0 has value 1.0, Beam 1 has 2.0, etc.</pre></td></tr><tr><td class='line-number'><a name='L82' href='#L82'><pre>82</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let source_cpu = Array4::from_shape_fn(</pre></td></tr><tr><td class='line-number'><a name='L83' href='#L83'><pre>83</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        (num_beams, num_heads, capacity, head_dim),</pre></td></tr><tr><td class='line-number'><a name='L84' href='#L84'><pre>84</pre></a></td><td class='covered-line'><pre>581k</pre></td><td class='code'><pre>        |(b, _, s, _)| {</pre></td></tr><tr><td class='line-number'><a name='L85' href='#L85'><pre>85</pre></a></td><td class='covered-line'><pre>581k</pre></td><td class='code'><pre>            if s &lt; CURRENT_SEQ_LEN {</pre></td></tr><tr><td class='line-number'><a name='L86' href='#L86'><pre>86</pre></a></td><td class='covered-line'><pre>8.19k</pre></td><td class='code'><pre>                (b + 1) as f32 // Beam 0 -&gt; 1.0, Beam 1 -&gt; 2.0, etc.</pre></td></tr><tr><td class='line-number'><a name='L87' href='#L87'><pre>87</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            } else {</pre></td></tr><tr><td class='line-number'><a name='L88' href='#L88'><pre>88</pre></a></td><td class='covered-line'><pre>573k</pre></td><td class='code'><pre>                0.0 // The rest of the cache is unused</pre></td></tr><tr><td class='line-number'><a name='L89' href='#L89'><pre>89</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            }</pre></td></tr><tr><td class='line-number'><a name='L90' href='#L90'><pre>90</pre></a></td><td class='covered-line'><pre>581k</pre></td><td class='code'><pre>        },</pre></td></tr><tr><td class='line-number'><a name='L91' href='#L91'><pre>91</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    );</pre></td></tr><tr><td class='line-number'><a name='L92' href='#L92'><pre>92</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let source_gpu = GpuTensor::from_ndarray(&amp;context, &amp;source_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L93' href='#L93'><pre>93</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L94' href='#L94'><pre>94</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 2. THE CRITICAL REORDER INDICES from your log ---</pre></td></tr><tr><td class='line-number'><a name='L95' href='#L95'><pre>95</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // [UPDATE] Parent beam indices for reorder: [0, 0, 1, 0]</pre></td></tr><tr><td class='line-number'><a name='L96' href='#L96'><pre>96</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let parent_indices_cpu = Array1::from(vec![0u32, 0, 1, 0]);</pre></td></tr><tr><td class='line-number'><a name='L97' href='#L97'><pre>97</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let indices_gpu = GpuTensor::from_ndarray(&amp;context, &amp;parent_indices_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L98' href='#L98'><pre>98</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L99' href='#L99'><pre>99</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 3. COMPUTE CPU GROUND TRUTH ---</pre></td></tr><tr><td class='line-number'><a name='L100' href='#L100'><pre>100</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let mut expected_cpu = Array4::zeros(source_cpu.dim());</pre></td></tr><tr><td class='line-number'><a name='L101' href='#L101'><pre>101</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>    for new_beam_idx in 0..<div class='tooltip'>num_beams<span class='tooltip-content'>1</span></div> {</pre></td></tr><tr><td class='line-number'><a name='L102' href='#L102'><pre>102</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let parent_beam_idx = parent_indices_cpu[new_beam_idx] as usize;</pre></td></tr><tr><td class='line-number'><a name='L103' href='#L103'><pre>103</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let mut dest_slice = expected_cpu.slice_mut(s![new_beam_idx, .., .., ..]);</pre></td></tr><tr><td class='line-number'><a name='L104' href='#L104'><pre>104</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        let src_slice = source_cpu.slice(s![parent_beam_idx, .., .., ..]);</pre></td></tr><tr><td class='line-number'><a name='L105' href='#L105'><pre>105</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>        dest_slice.assign(&amp;src_slice);</pre></td></tr><tr><td class='line-number'><a name='L106' href='#L106'><pre>106</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L107' href='#L107'><pre>107</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L108' href='#L108'><pre>108</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 4. GPU EXECUTION ---</pre></td></tr><tr><td class='line-number'><a name='L109' href='#L109'><pre>109</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let output_gpu = GpuTensor::uninitialized(&amp;context, source_cpu.shape().to_vec(), source_gpu.dtype(), &quot;Reorder Dst&quot;);</pre></td></tr><tr><td class='line-number'><a name='L110' href='#L110'><pre>110</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let mut encoder = context.device.create_command_encoder(&amp;Default::default());</pre></td></tr><tr><td class='line-number'><a name='L111' href='#L111'><pre>111</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    reorder_kernel.encode(</pre></td></tr><tr><td class='line-number'><a name='L112' href='#L112'><pre>112</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        &amp;mut encoder,</pre></td></tr><tr><td class='line-number'><a name='L113' href='#L113'><pre>113</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        &amp;source_gpu,</pre></td></tr><tr><td class='line-number'><a name='L114' href='#L114'><pre>114</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        &amp;output_gpu,</pre></td></tr><tr><td class='line-number'><a name='L115' href='#L115'><pre>115</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        &amp;indices_gpu,</pre></td></tr><tr><td class='line-number'><a name='L116' href='#L116'><pre>116</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        CURRENT_SEQ_LEN, // Use the correct sequence length</pre></td></tr><tr><td class='line-number'><a name='L117' href='#L117'><pre>117</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    );</pre></td></tr><tr><td class='line-number'><a name='L118' href='#L118'><pre>118</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    context.queue.submit(Some(encoder.finish()));</pre></td></tr><tr><td class='line-number'><a name='L119' href='#L119'><pre>119</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L120' href='#L120'><pre>120</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 5. VERIFY ---</pre></td></tr><tr><td class='line-number'><a name='L121' href='#L121'><pre>121</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let actual_gpu_result = read_gpu_tensor(&amp;output_gpu).await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L122' href='#L122'><pre>122</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    assert_eq!(expected_cpu, actual_gpu_result, <div class='tooltip'><span class='region red'>&quot;GPU reorder result does not match CPU ground truth for the failure case.&quot;</span><span class='tooltip-content'>0</span></div>);</pre></td></tr><tr><td class='line-number'><a name='L123' href='#L123'><pre>123</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L124' href='#L124'><pre>124</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    println!(&quot;✅ GPU reorder kernel correctly simulates the Step 2 reorder!&quot;);</pre></td></tr><tr><td class='line-number'><a name='L125' href='#L125'><pre>125</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L126' href='#L126'><pre>126</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // --- 6. ANALYSIS: Why does &quot;Rust Rust&quot; happen? ---</pre></td></tr><tr><td class='line-number'><a name='L127' href='#L127'><pre>127</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Let&apos;s look at the new state of Beam 0. It inherited its history from old Beam 0.</pre></td></tr><tr><td class='line-number'><a name='L128' href='#L128'><pre>128</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // The history contains the token &quot;Rust&quot;.</pre></td></tr><tr><td class='line-number'><a name='L129' href='#L129'><pre>129</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let new_beam_0_history_val = expected_cpu[[0, 0, 0, 0]];</pre></td></tr><tr><td class='line-number'><a name='L130' href='#L130'><pre>130</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    assert_eq!(new_beam_0_history_val, 1.0);</pre></td></tr><tr><td class='line-number'><a name='L131' href='#L131'><pre>131</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L132' href='#L132'><pre>132</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Now look at the new state of Beam 2. It inherited its history from old Beam 1.</pre></td></tr><tr><td class='line-number'><a name='L133' href='#L133'><pre>133</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // Old Beam 1&apos;s history did NOT contain &quot;Rust&quot;.</pre></td></tr><tr><td class='line-number'><a name='L134' href='#L134'><pre>134</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let new_beam_2_history_val = expected_cpu[[2, 0, 0, 0]];</pre></td></tr><tr><td class='line-number'><a name='L135' href='#L135'><pre>135</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    assert_eq!(new_beam_2_history_val, 2.0);</pre></td></tr><tr><td class='line-number'><a name='L136' href='#L136'><pre>136</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L137' href='#L137'><pre>137</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // The log shows the next tokens are [23083, 20, 23083, 128]</pre></td></tr><tr><td class='line-number'><a name='L138' href='#L138'><pre>138</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // The parent beams are             [0,     0,  1,     0]</pre></td></tr><tr><td class='line-number'><a name='L139' href='#L139'><pre>139</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    //</pre></td></tr><tr><td class='line-number'><a name='L140' href='#L140'><pre>140</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // This means:</pre></td></tr><tr><td class='line-number'><a name='L141' href='#L141'><pre>141</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // - New Beam 0 gets token &quot;Rust&quot; and history from Old Beam 0. History is now [&quot;Rust&quot;, &quot;Rust&quot;]</pre></td></tr><tr><td class='line-number'><a name='L142' href='#L142'><pre>142</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // - New Beam 1 gets token &quot;The&quot; and history from Old Beam 0. History is now [&quot;Rust&quot;, &quot;The&quot;]</pre></td></tr><tr><td class='line-number'><a name='L143' href='#L143'><pre>143</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // - New Beam 2 gets token &quot;Rust&quot; and history from Old Beam 1. History is now [&quot;The&quot;, &quot;Rust&quot;]</pre></td></tr><tr><td class='line-number'><a name='L144' href='#L144'><pre>144</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // - New Beam 3 gets token &quot;&apos;&quot; and history from Old Beam 0. History is now [&quot;Rust&quot;, &quot;&apos;&quot;]</pre></td></tr><tr><td class='line-number'><a name='L145' href='#L145'><pre>145</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    //</pre></td></tr><tr><td class='line-number'><a name='L146' href='#L146'><pre>146</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // The &quot;Rust Rust&quot; happens because the penalty `no_repeat_ngram_size: 3` does not</pre></td></tr><tr><td class='line-number'><a name='L147' href='#L147'><pre>147</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // prevent a bigram repeat. The reorder logic is correct. The problem is that the</pre></td></tr><tr><td class='line-number'><a name='L148' href='#L148'><pre>148</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // generation logic ALLOWS this choice to be made.</pre></td></tr><tr><td class='line-number'><a name='L149' href='#L149'><pre>149</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // The ONLY reason the CPU works is due to floating point differences making another</pre></td></tr><tr><td class='line-number'><a name='L150' href='#L150'><pre>150</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // token slightly more likely. The GPU is not wrong, it&apos;s just exposing the flaw</pre></td></tr><tr><td class='line-number'><a name='L151' href='#L151'><pre>151</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    // in the penalty configuration.</pre></td></tr><tr><td class='line-number'><a name='L152' href='#L152'><pre>152</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    println!(&quot;Analysis complete: The reorder kernel is correct. The divergence is caused by a logic flaw (penalty config) exposed by GPU floating point arithmetic.&quot;);</pre></td></tr><tr><td class='line-number'><a name='L153' href='#L153'><pre>153</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L154' href='#L154'><pre>154</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    Ok(())</pre></td></tr><tr><td class='line-number'><a name='L155' href='#L155'><pre>155</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>}</pre></td></tr></table></div></body></html>