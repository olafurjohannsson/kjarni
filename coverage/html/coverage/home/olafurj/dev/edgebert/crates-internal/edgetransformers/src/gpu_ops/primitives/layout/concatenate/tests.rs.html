<!doctype html><html><head><meta name='viewport' content='width=device-width,initial-scale=1'><meta charset='UTF-8'><link rel='stylesheet' type='text/css' href='../../../../../../../../../../../../style.css'><script src='../../../../../../../../../../../../control.js'></script></head><body><h2>Coverage Report</h2><h4>Created: 2025-12-04 22:30</h4><span class='control'><a href='javascript:next_line()'>next uncovered line (L)</a>, <a href='javascript:next_region()'>next uncovered region (R)</a>, <a href='javascript:next_branch()'>next uncovered branch (B)</a></span><div class='centered'><table><div class='source-name-title'><pre>/home/olafurj/dev/edgebert/crates-internal/edgetransformers/src/gpu_ops/primitives/layout/concatenate/tests.rs</pre></div><tr><td><pre>Line</pre></td><td><pre>Count</pre></td><td><pre>Source</pre></td></tr><tr><td class='line-number'><a name='L1' href='#L1'><pre>1</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_context::WgpuContext;</pre></td></tr><tr><td class='line-number'><a name='L2' href='#L2'><pre>2</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_ops::primitives::layout::concatenate::GpuConcatenate;</pre></td></tr><tr><td class='line-number'><a name='L3' href='#L3'><pre>3</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu_ops::GpuTensor;</pre></td></tr><tr><td class='line-number'><a name='L4' href='#L4'><pre>4</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use anyhow::Result;</pre></td></tr><tr><td class='line-number'><a name='L5' href='#L5'><pre>5</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use ndarray::{Array, Array4, Axis};</pre></td></tr><tr><td class='line-number'><a name='L6' href='#L6'><pre>6</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use std::sync::Arc;</pre></td></tr><tr><td class='line-number'><a name='L7' href='#L7'><pre>7</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L8' href='#L8'><pre>8</pre></a></td><td class='skipped-line'></td><td class='code'><pre>// You will need a `read_gpu_tensor` helper in this test module.</pre></td></tr><tr><td class='line-number'><a name='L9' href='#L9'><pre>9</pre></a></td><td class='skipped-line'></td><td class='code'><pre>// Helper to read a GPU tensor back to a generic ndarray for comparison.</pre></td></tr><tr><td class='line-number'><a name='L10' href='#L10'><pre>10</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>async fn read_gpu_tensor&lt;D: ndarray::Dimension&gt;(tensor: &amp;GpuTensor) -&gt; Result&lt;Array&lt;f32, D&gt;&gt; {</pre></td></tr><tr><td class='line-number'><a name='L11' href='#L11'><pre>11</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let shape = tensor.shape().to_vec();</pre></td></tr><tr><td class='line-number'><a name='L12' href='#L12'><pre>12</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let raw_data = tensor.read_raw_data().await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L13' href='#L13'><pre>13</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let data_slice: &amp;[f32] = bytemuck::cast_slice(&amp;raw_data);</pre></td></tr><tr><td class='line-number'><a name='L14' href='#L14'><pre>14</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    Ok(Array::from_shape_vec(shape, data_slice.to_vec())<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div></pre></td></tr><tr><td class='line-number'><a name='L15' href='#L15'><pre>15</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        .into_dimensionality::&lt;D&gt;()</pre></td></tr><tr><td class='line-number'><a name='L16' href='#L16'><pre>16</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        .unwrap())</pre></td></tr><tr><td class='line-number'><a name='L17' href='#L17'><pre>17</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L18' href='#L18'><pre>18</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L19' href='#L19'><pre>19</pre></a></td><td class='skipped-line'></td><td class='code'><pre>#[tokio::test]</pre></td></tr><tr><td class='line-number'><a name='L20' href='#L20'><pre>20</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>async fn test_gpu_concatenate_parity() -&gt; Result&lt;()&gt; {</pre></td></tr><tr><td class='line-number'><a name='L21' href='#L21'><pre>21</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let context = WgpuContext::new().await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L22' href='#L22'><pre>22</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let concat_kernel = GpuConcatenate::new(&amp;context);</pre></td></tr><tr><td class='line-number'><a name='L23' href='#L23'><pre>23</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let a_shape = (1, 12, 10, 64);</pre></td></tr><tr><td class='line-number'><a name='L24' href='#L24'><pre>24</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let b_shape = (1, 12, 1, 64);</pre></td></tr><tr><td class='line-number'><a name='L25' href='#L25'><pre>25</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let concat_axis = 2; // Sequence dimension</pre></td></tr><tr><td class='line-number'><a name='L26' href='#L26'><pre>26</pre></a></td><td class='covered-line'><pre>7.68k</pre></td><td class='code'><pre>    let <div class='tooltip'>a_cpu<span class='tooltip-content'>1</span></div> = <div class='tooltip'>Array4::from_shape_fn<span class='tooltip-content'>1</span></div>(<div class='tooltip'>a_shape<span class='tooltip-content'>1</span></div>, |(i, j, k, l)| (i+j+k+l) as f32);</pre></td></tr><tr><td class='line-number'><a name='L27' href='#L27'><pre>27</pre></a></td><td class='covered-line'><pre>768</pre></td><td class='code'><pre>    let <div class='tooltip'>b_cpu<span class='tooltip-content'>1</span></div> = <div class='tooltip'>Array4::from_shape_fn<span class='tooltip-content'>1</span></div>(<div class='tooltip'>b_shape<span class='tooltip-content'>1</span></div>, |(i, j, k, l)| (i+j+k+l) as f32 * -1.0);</pre></td></tr><tr><td class='line-number'><a name='L28' href='#L28'><pre>28</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let a_gpu = GpuTensor::from_ndarray(&amp;context, &amp;a_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L29' href='#L29'><pre>29</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let b_gpu = GpuTensor::from_ndarray(&amp;context, &amp;b_cpu)<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L30' href='#L30'><pre>30</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let expected_cpu = ndarray::concatenate(Axis(concat_axis), &amp;[a_cpu.view(), b_cpu.view()])<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L31' href='#L31'><pre>31</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let output_shape = expected_cpu.shape().to_vec();</pre></td></tr><tr><td class='line-number'><a name='L32' href='#L32'><pre>32</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let output_gpu = GpuTensor::uninitialized(&amp;context, output_shape, a_gpu.dtype(), &quot;Concat Output&quot;);</pre></td></tr><tr><td class='line-number'><a name='L33' href='#L33'><pre>33</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let mut encoder = context.device.create_command_encoder(&amp;Default::default());</pre></td></tr><tr><td class='line-number'><a name='L34' href='#L34'><pre>34</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    concat_kernel.encode(&amp;mut encoder, &amp;[&amp;a_gpu, &amp;b_gpu], &amp;output_gpu, concat_axis);</pre></td></tr><tr><td class='line-number'><a name='L35' href='#L35'><pre>35</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    context.queue.submit(Some(encoder.finish()));</pre></td></tr><tr><td class='line-number'><a name='L36' href='#L36'><pre>36</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    let actual_gpu_result: Array4&lt;f32&gt; = read_gpu_tensor(&amp;output_gpu).await<div class='tooltip'><span class='region red'>?</span><span class='tooltip-content'>0</span></div>;</pre></td></tr><tr><td class='line-number'><a name='L37' href='#L37'><pre>37</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    assert_eq!(expected_cpu, actual_gpu_result, <div class='tooltip'><span class='region red'>&quot;GPU concatenate result does not match CPU ground truth.&quot;</span><span class='tooltip-content'>0</span></div>);</pre></td></tr><tr><td class='line-number'><a name='L38' href='#L38'><pre>38</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    Ok(())</pre></td></tr><tr><td class='line-number'><a name='L39' href='#L39'><pre>39</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>}</pre></td></tr></table></div></body></html>